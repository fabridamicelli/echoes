
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Echo State Networks in Python">
      
      
        <meta name="author" content="Fabrizio Damicelli">
      
      
        <link rel="canonical" href="https://fabridamicelli.github.io/echoes/api/ESNGenerator/">
      
      
        <link rel="prev" href="../ESNRegressor/">
      
      
        <link rel="next" href="../plotting/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.1">
    
    
      
        <title>ESNGenerator - echoes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.a40c8224.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#echoes.esn._generator.ESNGenerator" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="echoes" class="md-header__button md-logo" aria-label="echoes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            echoes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ESNGenerator
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/fabridamicelli/echoes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="echoes" class="md-nav__button md-logo" aria-label="echoes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    echoes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/fabridamicelli/echoes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What are Echo State Networks?
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/notebooks/regressor-sincos/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ESNRegressor (sin-cos)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/notebooks/generator-mackeyglass17/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ESNGenerator (Mackey-Glass)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/notebooks/reservoir-activity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Plot Reservoir Activity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/notebooks/regressor-gridsearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ESNRegressor GridSearchCV
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples/notebooks/regressor-pipeline-and-gridsearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ESNRegressor, GridSearchCV, Pipeline
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ESNRegressor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ESNRegressor
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    ESNGenerator
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    ESNGenerator
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator" class="md-nav__link">
    <span class="md-ellipsis">
      ESNGenerator
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ESNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator--attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator.score" class="md-nav__link">
    <span class="md-ellipsis">
      score
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../plotting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plotting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator" class="md-nav__link">
    <span class="md-ellipsis">
      ESNGenerator
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ESNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator--attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#echoes.esn._generator.ESNGenerator.score" class="md-nav__link">
    <span class="md-ellipsis">
      score
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>ESNGenerator</h1>

<div class="doc doc-object doc-class">



<a id="echoes.esn._generator.ESNGenerator"></a>
    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="sklearn.base.MultiOutputMixin">MultiOutputMixin</span></code>, <code><span title="sklearn.base.RegressorMixin">RegressorMixin</span></code>, <code><span title="echoes.esn._base.ESNBase">ESNBase</span></code></p>


        <p>The number of inputs (n_inputs) is always 1 and n_outputs is infered from passed
data.
It uses always feedback, so that is not a parameter anymore (always True).</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>n_steps</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int, default=100
Number of steps to generate pattern (used by predict method).</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_reservoir</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int, optional, default=100
Number of reservoir neurons. Only used if W is not passed.
If W is passed, n_reservoir gets overwritten with len(W).
Either n_reservoir or W must be passed.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>W</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>np.ndarray of shape (n_reservoir, n_reservoir), optional, default=None
Reservoir weights matrix. If None, random weights are used (uniformly
distributed around 0, ie., in [-0.5, 0.5).
Be careful with the distribution of W values. Wrong W initialization
might drastically affect test performance (even with reasonable good
training fit).
Spectral radius will be adjusted in all cases.
Either n_reservoir or W must be passed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spectral_radius</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float, default=.99
Spectral radius of the reservoir weights matrix (W).
Spectral radius will be adjusted in all cases (also with user specified W).</p>
              </div>
            </td>
            <td>
                  <code>0.99</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>W_in</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>np.ndarray of shape (n_reservoir, 1+n_inputs) (1-&gt;bias), optional,
default None.
Input weights matrix by which input signal is multiplied.
If None, random weights are used.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>W_fb</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>np.ndarray of shape(n_reservoir, n_outputs), optional, default None.
Feedback weights matrix by which feedback is multiplied in case of feedback.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sparsity</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float, optional, default=0
Proportion of the reservoir matrix weights forced to be zero.
Note that with default W (centered around 0), the actual sparsity will
be slightly more than the specified.
If W is passed, sparsity will be ignored.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>noise</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float, optional, default=0
Scaling factor of the (uniform) noise input added to neurons at each step.
This is used for regularization purposes and should typically be
very small, e.g. 0.0001 or 1e-5.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>leak_rate</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float, optional, default=1
Leaking rate applied to the neurons at each step.
Default is 1, which is no leaking. 0 would be total leakeage.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bias</code>
            </td>
            <td>
                  <code><span title="float">float</span> | <span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int, float or np.ndarray, optional, default=1
Value of the bias neuron, injected at each time to the reservoir neurons.
If int or float, all neurons receive the same.
If np.ndarray is must be of length n_reservoir.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function (numba jitted), optional, default=tanh
Non-linear activation function applied to the neurons at each step.
For numba acceleration, it must be a jitted function.
Basic activation functions as tanh, sigmoid, relu are already available
in echoe.utils. Either use those or write a custom one decorated with
numba njit.</p>
              </div>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="echoes.utils.tanh" href="../utils/#echoes.utils.tanh">tanh</a></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>activation_out</code>
            </td>
            <td>
                  <code><span title="typing.Callable">Callable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>function, optional, default=identity
Activation function applied to the outputs. In other words, it is assumed
that targets = f(outputs). So the output produced must be transformed.</p>
              </div>
            </td>
            <td>
                  <code><span title="echoes.utils.identity">identity</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fit_only_states</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool,default=False
If True, outgoing weights (W_out) are computed fitting only the reservoir
states. Inputs and bias are still use to drive reservoir activity, but
ignored for fitting W_out, both in the training and prediction phase.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>regression_method</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str, optional, default "pinv" (pseudoinverse).
Method to solve the linear regression to find out outgoing weights.
One of ["pinv", "ridge"].
If "ridge", ridge_* parameters will be used.</p>
              </div>
            </td>
            <td>
                  <code>&#39;pinv&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ridge_alpha</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float, ndarray of shape (n_outputs,), default=None
Regularization coefficient used for Ridge regression.
Larger values specify stronger regularization.
If an array is passed, penalties are assumed to be specific to the targets.
Hence they must correspond in number.
Default is None to make sure one deliberately sets this since it is
a crucial parameter. See sklearn Ridge documentation for details.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ridge_fit_intercept</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool, optional, default=False
If True, intercept is fit in Ridge regression. Default False.
See sklearn Ridge documentation for details.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ridge_max_iter</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int, default=None
Maximum number of iterations for conjugate gradient solver.
See sklearn Ridge documentation for details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ridge_tol</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float, default=1e-3
Precision of the solution.
See sklearn Ridge documentation for details.</p>
              </div>
            </td>
            <td>
                  <code>0.001</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ridge_solver</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str, optional, default="auto"
Solver to use in the Ridge regression.
One of ["auto", "svd", "cholesky", "lsqr", "sparse_cg", "sag", "saga"].
See sklearn Ridge documentation for details.</p>
              </div>
            </td>
            <td>
                  <code>&#39;auto&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ridge_sample_weight</code>
            </td>
            <td>
                  <code><span title="float">float</span> | <span title="numpy.ndarray">ndarray</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float or ndarray of shape (n_samples,), default=None
Individual weights for each sample.
If given a float, every sample will have the same weight.
See sklearn Ridge documentation for details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_transient</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int, optional, default=0
Number of activity initial steps removed (not considered for training)
in order to avoid initial instabilities.
Default is 0, but this is something one definitely might want to tweak.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>random_state</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int, RandomState instance, default=None
The seed of the pseudo random number generator used to generate weight
matrices, to generate noise inyected to reservoir neurons (regularization)
and it is passed to the ridge solver in case regression_method=ridge.
From sklearn:
  If int, random_state is the seed used by the random number generator;
  If RandomState instance, random_state is the random number generator;
  If None, the random number generator is the RandomState instance used
  by <code>np.random</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>store_states_train</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool, optional, default=False
If True, time series series of reservoir neurons during training are stored
in the object attribute states_train_.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>store_states_pred</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool, optional, default=False
If True, time series series of reservoir neurons during prediction are
stored in the object attribute states_pred_.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>
        <h4 id="echoes.esn._generator.ESNGenerator--attributes">Attributes:<a class="headerlink" href="#echoes.esn._generator.ESNGenerator--attributes" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><code><span class="o">-</span><span class="w"> </span><span class="n">W_out_</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">array</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">(</span><span class="n">n_outputs</span><span class="p">,</span><span class="w"> </span><span class="n">n_inputs</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">n_reservoir</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mh">1</span><span class="p">).</span>
<span class="w">    </span><span class="n">Outgoing</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">after</span><span class="w"> </span><span class="n">fitting</span><span class="w"> </span><span class="n">linear</span><span class="w"> </span><span class="n">regression</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">predict</span><span class="w"> </span><span class="n">outputs</span><span class="p">.</span>
<span class="o">-</span><span class="w"> </span><span class="nl">training_prediction_:</span><span class="w"> </span><span class="n">array</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span><span class="w"> </span><span class="n">n_outputs</span><span class="p">).</span>
<span class="w">    </span><span class="n">Predicted</span><span class="w"> </span><span class="k">output</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">data</span><span class="p">.</span>
<span class="o">-</span><span class="w"> </span><span class="nl">states_train_:</span><span class="w"> </span><span class="n">array</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span><span class="w"> </span><span class="n">n_reservoir</span><span class="p">),</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="n">False</span><span class="p">.</span>
<span class="w">    </span><span class="n">If</span><span class="w"> </span><span class="n">store_states_train</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">True</span><span class="p">,</span><span class="w"> </span><span class="n">states</span><span class="w"> </span><span class="n">matrix</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">stored</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">visualizing</span>
<span class="w">    </span><span class="n">reservoir</span><span class="w"> </span><span class="n">neurons</span><span class="w"> </span><span class="n">activity</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">training</span><span class="p">.</span>
<span class="o">-</span><span class="w"> </span><span class="nl">states_pred_:</span><span class="w"> </span><span class="n">array</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span><span class="w"> </span><span class="n">n_reservoir</span><span class="p">),</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="n">False</span><span class="p">.</span>
<span class="w">    </span><span class="n">If</span><span class="w"> </span><span class="n">store_states_pred</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">True</span><span class="p">,</span><span class="w"> </span><span class="n">states</span><span class="w"> </span><span class="n">matrix</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">stored</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">visualizing</span>
<span class="w">    </span><span class="n">reservoir</span><span class="w"> </span><span class="n">neurons</span><span class="w"> </span><span class="n">activity</span><span class="w"> </span><span class="n">during</span><span class="w"> </span><span class="n">prediction</span><span class="w"> </span><span class="p">(</span><span class="n">test</span><span class="p">).</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>src/echoes/esn/_generator.py</code></summary>
                <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ESNGenerator</span><span class="p">(</span><span class="n">MultiOutputMixin</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">ESNBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The number of inputs (n_inputs) is always 1 and n_outputs is infered from passed</span>
<span class="sd">    data.</span>
<span class="sd">    It uses always feedback, so that is not a parameter anymore (always True).</span>

<span class="sd">    Arguments:</span>
<span class="sd">        n_steps: int, default=100</span>
<span class="sd">            Number of steps to generate pattern (used by predict method).</span>
<span class="sd">        n_reservoir: int, optional, default=100</span>
<span class="sd">            Number of reservoir neurons. Only used if W is not passed.</span>
<span class="sd">            If W is passed, n_reservoir gets overwritten with len(W).</span>
<span class="sd">            Either n_reservoir or W must be passed.</span>
<span class="sd">        W: np.ndarray of shape (n_reservoir, n_reservoir), optional, default=None</span>
<span class="sd">            Reservoir weights matrix. If None, random weights are used (uniformly</span>
<span class="sd">            distributed around 0, ie., in [-0.5, 0.5).</span>
<span class="sd">            Be careful with the distribution of W values. Wrong W initialization</span>
<span class="sd">            might drastically affect test performance (even with reasonable good</span>
<span class="sd">            training fit).</span>
<span class="sd">            Spectral radius will be adjusted in all cases.</span>
<span class="sd">            Either n_reservoir or W must be passed.</span>
<span class="sd">        spectral_radius: float, default=.99</span>
<span class="sd">            Spectral radius of the reservoir weights matrix (W).</span>
<span class="sd">            Spectral radius will be adjusted in all cases (also with user specified W).</span>
<span class="sd">        W_in: np.ndarray of shape (n_reservoir, 1+n_inputs) (1-&gt;bias), optional,</span>
<span class="sd">            default None.</span>
<span class="sd">            Input weights matrix by which input signal is multiplied.</span>
<span class="sd">            If None, random weights are used.</span>
<span class="sd">        W_fb: np.ndarray of shape(n_reservoir, n_outputs), optional, default None.</span>
<span class="sd">            Feedback weights matrix by which feedback is multiplied in case of feedback.</span>
<span class="sd">        sparsity: float, optional, default=0</span>
<span class="sd">            Proportion of the reservoir matrix weights forced to be zero.</span>
<span class="sd">            Note that with default W (centered around 0), the actual sparsity will</span>
<span class="sd">            be slightly more than the specified.</span>
<span class="sd">            If W is passed, sparsity will be ignored.</span>
<span class="sd">        noise: float, optional, default=0</span>
<span class="sd">            Scaling factor of the (uniform) noise input added to neurons at each step.</span>
<span class="sd">            This is used for regularization purposes and should typically be</span>
<span class="sd">            very small, e.g. 0.0001 or 1e-5.</span>
<span class="sd">        leak_rate: float, optional, default=1</span>
<span class="sd">            Leaking rate applied to the neurons at each step.</span>
<span class="sd">            Default is 1, which is no leaking. 0 would be total leakeage.</span>
<span class="sd">        bias: int, float or np.ndarray, optional, default=1</span>
<span class="sd">            Value of the bias neuron, injected at each time to the reservoir neurons.</span>
<span class="sd">            If int or float, all neurons receive the same.</span>
<span class="sd">            If np.ndarray is must be of length n_reservoir.</span>
<span class="sd">        activation: function (numba jitted), optional, default=tanh</span>
<span class="sd">            Non-linear activation function applied to the neurons at each step.</span>
<span class="sd">            For numba acceleration, it must be a jitted function.</span>
<span class="sd">            Basic activation functions as tanh, sigmoid, relu are already available</span>
<span class="sd">            in echoe.utils. Either use those or write a custom one decorated with</span>
<span class="sd">            numba njit.</span>
<span class="sd">        activation_out: function, optional, default=identity</span>
<span class="sd">            Activation function applied to the outputs. In other words, it is assumed</span>
<span class="sd">            that targets = f(outputs). So the output produced must be transformed.</span>
<span class="sd">        fit_only_states: bool,default=False</span>
<span class="sd">            If True, outgoing weights (W_out) are computed fitting only the reservoir</span>
<span class="sd">            states. Inputs and bias are still use to drive reservoir activity, but</span>
<span class="sd">            ignored for fitting W_out, both in the training and prediction phase.</span>
<span class="sd">        regression_method: str, optional, default &quot;pinv&quot; (pseudoinverse).</span>
<span class="sd">            Method to solve the linear regression to find out outgoing weights.</span>
<span class="sd">            One of [&quot;pinv&quot;, &quot;ridge&quot;].</span>
<span class="sd">            If &quot;ridge&quot;, ridge_* parameters will be used.</span>
<span class="sd">        ridge_alpha: float, ndarray of shape (n_outputs,), default=None</span>
<span class="sd">            Regularization coefficient used for Ridge regression.</span>
<span class="sd">            Larger values specify stronger regularization.</span>
<span class="sd">            If an array is passed, penalties are assumed to be specific to the targets.</span>
<span class="sd">            Hence they must correspond in number.</span>
<span class="sd">            Default is None to make sure one deliberately sets this since it is</span>
<span class="sd">            a crucial parameter. See sklearn Ridge documentation for details.</span>
<span class="sd">        ridge_fit_intercept: bool, optional, default=False</span>
<span class="sd">            If True, intercept is fit in Ridge regression. Default False.</span>
<span class="sd">            See sklearn Ridge documentation for details.</span>
<span class="sd">        ridge_max_iter: int, default=None</span>
<span class="sd">            Maximum number of iterations for conjugate gradient solver.</span>
<span class="sd">            See sklearn Ridge documentation for details.</span>
<span class="sd">        ridge_tol: float, default=1e-3</span>
<span class="sd">            Precision of the solution.</span>
<span class="sd">            See sklearn Ridge documentation for details.</span>
<span class="sd">        ridge_solver: str, optional, default=&quot;auto&quot;</span>
<span class="sd">            Solver to use in the Ridge regression.</span>
<span class="sd">            One of [&quot;auto&quot;, &quot;svd&quot;, &quot;cholesky&quot;, &quot;lsqr&quot;, &quot;sparse_cg&quot;, &quot;sag&quot;, &quot;saga&quot;].</span>
<span class="sd">            See sklearn Ridge documentation for details.</span>
<span class="sd">        ridge_sample_weight: float or ndarray of shape (n_samples,), default=None</span>
<span class="sd">            Individual weights for each sample.</span>
<span class="sd">            If given a float, every sample will have the same weight.</span>
<span class="sd">            See sklearn Ridge documentation for details.</span>
<span class="sd">        n_transient: int, optional, default=0</span>
<span class="sd">            Number of activity initial steps removed (not considered for training)</span>
<span class="sd">            in order to avoid initial instabilities.</span>
<span class="sd">            Default is 0, but this is something one definitely might want to tweak.</span>
<span class="sd">        random_state : int, RandomState instance, default=None</span>
<span class="sd">            The seed of the pseudo random number generator used to generate weight</span>
<span class="sd">            matrices, to generate noise inyected to reservoir neurons (regularization)</span>
<span class="sd">            and it is passed to the ridge solver in case regression_method=ridge.</span>
<span class="sd">            From sklearn:</span>
<span class="sd">              If int, random_state is the seed used by the random number generator;</span>
<span class="sd">              If RandomState instance, random_state is the random number generator;</span>
<span class="sd">              If None, the random number generator is the RandomState instance used</span>
<span class="sd">              by `np.random`.</span>
<span class="sd">        store_states_train: bool, optional, default=False</span>
<span class="sd">            If True, time series series of reservoir neurons during training are stored</span>
<span class="sd">            in the object attribute states_train_.</span>
<span class="sd">        store_states_pred: bool, optional, default=False</span>
<span class="sd">            If True, time series series of reservoir neurons during prediction are</span>
<span class="sd">            stored in the object attribute states_pred_.</span>

<span class="sd">    ### Attributes:</span>
<span class="sd">        - W_out_ : array of shape (n_outputs, n_inputs + n_reservoir + 1).</span>
<span class="sd">            Outgoing weights after fitting linear regression model to predict outputs.</span>
<span class="sd">        - training_prediction_: array of shape (n_samples, n_outputs).</span>
<span class="sd">            Predicted output on training data.</span>
<span class="sd">        - states_train_: array of shape (n_samples, n_reservoir), default False.</span>
<span class="sd">            If store_states_train is True, states matrix is stored for visualizing</span>
<span class="sd">            reservoir neurons activity during training.</span>
<span class="sd">        - states_pred_: array of shape (n_samples, n_reservoir), default False.</span>
<span class="sd">            If store_states_pred is True, states matrix is stored for visualizing</span>
<span class="sd">            reservoir neurons activity during prediction (test).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">n_reservoir</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spectral_radius</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span>
        <span class="n">W_in</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">W_fb</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sparsity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">leak_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">bias</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">input_scaling</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_shift</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">,</span>
        <span class="n">activation_out</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">identity</span><span class="p">,</span>
        <span class="n">fit_only_states</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">regression_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;pinv&quot;</span><span class="p">,</span>
        <span class="n">ridge_alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">ridge_fit_intercept</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">ridge_max_iter</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ridge_tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">ridge_solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">ridge_sample_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_transient</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">store_states_train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">store_states_pred</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir</span> <span class="o">=</span> <span class="n">n_reservoir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spectral_radius</span> <span class="o">=</span> <span class="n">spectral_radius</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_in</span> <span class="o">=</span> <span class="n">W_in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_fb</span> <span class="o">=</span> <span class="n">W_fb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparsity</span> <span class="o">=</span> <span class="n">sparsity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leak_rate</span> <span class="o">=</span> <span class="n">leak_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_scaling</span> <span class="o">=</span> <span class="n">input_scaling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shift</span> <span class="o">=</span> <span class="n">input_shift</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation_out</span> <span class="o">=</span> <span class="n">activation_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_only_states</span> <span class="o">=</span> <span class="n">fit_only_states</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_transient</span> <span class="o">=</span> <span class="n">n_transient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_states_train</span> <span class="o">=</span> <span class="n">store_states_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_states_pred</span> <span class="o">=</span> <span class="n">store_states_pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regression_method</span> <span class="o">=</span> <span class="n">regression_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ridge_alpha</span> <span class="o">=</span> <span class="n">ridge_alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ridge_fit_intercept</span> <span class="o">=</span> <span class="n">ridge_fit_intercept</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ridge_max_iter</span> <span class="o">=</span> <span class="n">ridge_max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ridge_tol</span> <span class="o">=</span> <span class="n">ridge_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ridge_solver</span> <span class="o">=</span> <span class="n">ridge_solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ridge_sample_weight</span> <span class="o">=</span> <span class="n">ridge_sample_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feedback</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Generator uses feedback always</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__sklearn_tags__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">tags</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__sklearn_tags__</span><span class="p">()</span>
        <span class="c1"># Allow multi-output since we can have several outputs</span>
        <span class="n">tags</span><span class="o">.</span><span class="n">target_tags</span><span class="o">.</span><span class="n">single_output</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># The output depends on reservoir state and thus is order-dependant, so we mark</span>
        <span class="c1"># it as non-determinstic</span>
        <span class="n">tags</span><span class="o">.</span><span class="n">non_deterministic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">tags</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ESNGenerator&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit Echo State model, i.e., find outgoing weights matrix (W_out) for later</span>
<span class="sd">        prediction.</span>
<span class="sd">        Bias is appended automatically to the inputs.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            X: None, always ignored. Argument kept only for API consistency.</span>
<span class="sd">                It is ignored as only the target sequence matters (outputs).</span>
<span class="sd">                A sequence of zeros will be fed in - matching the len(outputs) as</span>
<span class="sd">                initial condition.</span>
<span class="sd">            y: 2D np.ndarray of shape (n_samples,) or (n_samples, n_outputs),</span>
<span class="sd">                default=None.</span>
<span class="sd">                Target variable.</span>

<span class="sd">        Returns:</span>
<span class="sd">            self: returns an instance of self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle corner cases for sklearn compatibility</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># This error message has to be *exactly* like this for check_estimator test</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;requires y to be passed, but the target y is None&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;X must be None, ESNGenerator takes no X for prediction.&quot;</span>
                <span class="s2">&quot;The parameter is kept only for API consistency here.&quot;</span>
            <span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;numeric&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">y</span>

        <span class="c1"># Initialize matrices and random state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="c1"># Pattern generation takes no input, thus hardcode for later</span>
        <span class="c1"># construction of matrices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs_</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_in_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_incoming_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_reservoir_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_fb_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_feedback_weights</span><span class="p">()</span>

        <span class="n">check_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

        <span class="c1"># Make inputs zero</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">)</span>

        <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>  <span class="c1"># sanity check</span>

        <span class="c1"># Initialize reservoir model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reservoir_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_reservoir_neurons</span><span class="p">()</span>

        <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reservoir_</span><span class="o">.</span><span class="n">harvest_states</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Extend states matrix with inputs; i.e., make [h(t); x(t)]</span>
        <span class="n">full_states</span> <span class="o">=</span> <span class="n">states</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_only_states</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">states</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span>

        <span class="c1"># Solve for W_out using full states and outputs, excluding transient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_out_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_W_out</span><span class="p">(</span>
            <span class="n">full_states</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_transient</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_transient</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="p">)</span>
        <span class="c1"># Predict on training set (including the pass through the output nonlinearity)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_prediction_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_out</span><span class="p">(</span><span class="n">full_states</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_out_</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Keep last state for later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_state_</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_input_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_output_</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># Store reservoir activity</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_states_train</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">states_train_</span> <span class="o">=</span> <span class="n">states</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Last training state/input/output is used as initial test</span>
<span class="sd">        state/input/output and at each step the output of the network is reinjected</span>
<span class="sd">        as input for next prediction, thus no inputs are needed for prediction.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            X: None, always ignored, API consistency</span>

<span class="sd">        Returns:</span>
<span class="sd">            outputs: 2D np.ndarray of shape (n_steps, n_outputs)</span>
<span class="sd">             Predicted outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;X must be None, ESNGenerator takes no X for prediction.&quot;</span>
                <span class="s2">&quot;The parameter is kept only for API consistency here.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># TODO: add test</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;n_steps must be &gt;= 1&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;n_inputs must be == 1&quot;</span>

        <span class="c1"># Initialize predictions: begin with last state as first state</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">last_input_</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">last_state_</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">last_output_</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>  <span class="c1"># sanity check</span>

        <span class="c1"># Go through samples (steps) and predict for each of them</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">states</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reservoir_</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span>
                <span class="n">state_t</span><span class="o">=</span><span class="n">states</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span>
                <span class="n">X_t</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:],</span>
                <span class="n">y_t</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_only_states</span><span class="p">:</span>
                <span class="n">full_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">full_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">states</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:],</span> <span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]])</span>
            <span class="c1"># Predict</span>
            <span class="n">outputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_out</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_out_</span> <span class="o">@</span> <span class="n">full_states</span><span class="p">)</span>

            <span class="c1"># TODO: check: shoud we Update last_{input, states, outputs}_?</span>
            <span class="c1"># That would imply that succesively calls predict() render potentially</span>
            <span class="c1"># different results because we are updating the inner state.</span>
            <span class="c1"># Keep last state for later</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_state_</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_input_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_output_</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="c1"># Store reservoir activity</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_states_pred</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">states_pred_</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># discard first step (comes from fitting)</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># discard initial step (comes from training)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wrapper around sklearn r2_score with kwargs.</span>

<span class="sd">        From sklearn:</span>
<span class="sd">          R^2 (coefficient of determination) regression score function.</span>
<span class="sd">          Best possible score is 1.0 and it can be negative (because the model can be</span>
<span class="sd">          arbitrarily worse).</span>
<span class="sd">          A constant model that always predicts the expected value of y,</span>
<span class="sd">          disregarding the input features, would get a R^2 score of 0.0.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            X: None</span>
<span class="sd">                Not used, present for API consistency.</span>
<span class="sd">                Generative ESN predicts purely based on its generative outputs.</span>
<span class="sd">            y: 2D np.ndarray of shape (n_samples, ) or (n_samples, n_outputs)</span>
<span class="sd">                Target sequence, true values of the outputs.</span>
<span class="sd">            sample_weight: array-like of shape (n_samples,), default=None</span>
<span class="sd">                Sample weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">            score: float</span>
<span class="sd">                R2 score</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="echoes.esn._generator.ESNGenerator.fit" class="doc doc-heading">
            <code class=" language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#echoes.esn._generator.ESNGenerator.fit" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Fit Echo State model, i.e., find outgoing weights matrix (W_out) for later
prediction.
Bias is appended automatically to the inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None, always ignored. Argument kept only for API consistency.
It is ignored as only the target sequence matters (outputs).
A sequence of zeros will be fed in - matching the len(outputs) as
initial condition.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>2D np.ndarray of shape (n_samples,) or (n_samples, n_outputs),
default=None.
Target variable.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>self</code></td>            <td>
                  <code>&#39;ESNGenerator&#39;</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>returns an instance of self.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/echoes/esn/_generator.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ESNGenerator&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit Echo State model, i.e., find outgoing weights matrix (W_out) for later</span>
<span class="sd">    prediction.</span>
<span class="sd">    Bias is appended automatically to the inputs.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        X: None, always ignored. Argument kept only for API consistency.</span>
<span class="sd">            It is ignored as only the target sequence matters (outputs).</span>
<span class="sd">            A sequence of zeros will be fed in - matching the len(outputs) as</span>
<span class="sd">            initial condition.</span>
<span class="sd">        y: 2D np.ndarray of shape (n_samples,) or (n_samples, n_outputs),</span>
<span class="sd">            default=None.</span>
<span class="sd">            Target variable.</span>

<span class="sd">    Returns:</span>
<span class="sd">        self: returns an instance of self.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle corner cases for sklearn compatibility</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># This error message has to be *exactly* like this for check_estimator test</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;requires y to be passed, but the target y is None&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;X must be None, ESNGenerator takes no X for prediction.&quot;</span>
            <span class="s2">&quot;The parameter is kept only for API consistency here.&quot;</span>
        <span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;numeric&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">y</span>

    <span class="c1"># Initialize matrices and random state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">random_state_</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
    <span class="c1"># Pattern generation takes no input, thus hardcode for later</span>
    <span class="c1"># construction of matrices</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs_</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W_in_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_incoming_weights</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_reservoir_weights</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W_fb_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_feedback_weights</span><span class="p">()</span>

    <span class="n">check_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

    <span class="c1"># Make inputs zero</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">)</span>

    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>  <span class="c1"># sanity check</span>

    <span class="c1"># Initialize reservoir model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reservoir_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_reservoir_neurons</span><span class="p">()</span>

    <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reservoir_</span><span class="o">.</span><span class="n">harvest_states</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Extend states matrix with inputs; i.e., make [h(t); x(t)]</span>
    <span class="n">full_states</span> <span class="o">=</span> <span class="n">states</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_only_states</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">states</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span>

    <span class="c1"># Solve for W_out using full states and outputs, excluding transient</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W_out_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_solve_W_out</span><span class="p">(</span>
        <span class="n">full_states</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_transient</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_transient</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="p">)</span>
    <span class="c1"># Predict on training set (including the pass through the output nonlinearity)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_prediction_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_out</span><span class="p">(</span><span class="n">full_states</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_out_</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="c1"># Keep last state for later</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_state_</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_input_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_output_</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Store reservoir activity</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_states_train</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states_train_</span> <span class="o">=</span> <span class="n">states</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="echoes.esn._generator.ESNGenerator.predict" class="doc doc-heading">
            <code class=" language-python"><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#echoes.esn._generator.ESNGenerator.predict" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Last training state/input/output is used as initial test
state/input/output and at each step the output of the network is reinjected
as input for next prediction, thus no inputs are needed for prediction.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None, always ignored, API consistency</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>outputs</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>2D np.ndarray of shape (n_steps, n_outputs)
Predicted outputs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/echoes/esn/_generator.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Last training state/input/output is used as initial test</span>
<span class="sd">    state/input/output and at each step the output of the network is reinjected</span>
<span class="sd">    as input for next prediction, thus no inputs are needed for prediction.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        X: None, always ignored, API consistency</span>

<span class="sd">    Returns:</span>
<span class="sd">        outputs: 2D np.ndarray of shape (n_steps, n_outputs)</span>
<span class="sd">         Predicted outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;X must be None, ESNGenerator takes no X for prediction.&quot;</span>
            <span class="s2">&quot;The parameter is kept only for API consistency here.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># TODO: add test</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;n_steps must be &gt;= 1&quot;</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;n_inputs must be == 1&quot;</span>

    <span class="c1"># Initialize predictions: begin with last state as first state</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_inputs_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">last_input_</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>
    <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_state_</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reservoir_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_output_</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs_</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_</span><span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>  <span class="c1"># sanity check</span>

    <span class="c1"># Go through samples (steps) and predict for each of them</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">states</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reservoir_</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span>
            <span class="n">state_t</span><span class="o">=</span><span class="n">states</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span>
            <span class="n">X_t</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:],</span>
            <span class="n">y_t</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_only_states</span><span class="p">:</span>
            <span class="n">full_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">states</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:],</span> <span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]])</span>
        <span class="c1"># Predict</span>
        <span class="n">outputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_out</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_out_</span> <span class="o">@</span> <span class="n">full_states</span><span class="p">)</span>

        <span class="c1"># TODO: check: shoud we Update last_{input, states, outputs}_?</span>
        <span class="c1"># That would imply that succesively calls predict() render potentially</span>
        <span class="c1"># different results because we are updating the inner state.</span>
        <span class="c1"># Keep last state for later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_state_</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_input_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_output_</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Store reservoir activity</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">store_states_pred</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states_pred_</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># discard first step (comes from fitting)</span>

    <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># discard initial step (comes from training)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="echoes.esn._generator.ESNGenerator.score" class="doc doc-heading">
            <code class=" language-python"><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#echoes.esn._generator.ESNGenerator.score" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Wrapper around sklearn r2_score with kwargs.</p>


<details class="from-sklearn" open>
  <summary>From sklearn</summary>
  <p>R^2 (coefficient of determination) regression score function.
Best possible score is 1.0 and it can be negative (because the model can be
arbitrarily worse).
A constant model that always predicts the expected value of y,
disregarding the input features, would get a R^2 score of 0.0.</p>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None
Not used, present for API consistency.
Generative ESN predicts purely based on its generative outputs.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>2D np.ndarray of shape (n_samples, ) or (n_samples, n_outputs)
Target sequence, true values of the outputs.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sample_weight</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>array-like of shape (n_samples,), default=None
Sample weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
R2 score</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/echoes/esn/_generator.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper around sklearn r2_score with kwargs.</span>

<span class="sd">    From sklearn:</span>
<span class="sd">      R^2 (coefficient of determination) regression score function.</span>
<span class="sd">      Best possible score is 1.0 and it can be negative (because the model can be</span>
<span class="sd">      arbitrarily worse).</span>
<span class="sd">      A constant model that always predicts the expected value of y,</span>
<span class="sd">      disregarding the input features, would get a R^2 score of 0.0.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        X: None</span>
<span class="sd">            Not used, present for API consistency.</span>
<span class="sd">            Generative ESN predicts purely based on its generative outputs.</span>
<span class="sd">        y: 2D np.ndarray of shape (n_samples, ) or (n_samples, n_outputs)</span>
<span class="sd">            Target sequence, true values of the outputs.</span>
<span class="sd">        sample_weight: array-like of shape (n_samples,), default=None</span>
<span class="sd">            Sample weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        score: float</span>
<span class="sd">            R2 score</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 Maintained by <a href="https://twitter.com/fabridamicelli">Fabrizio</a>.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/fabridamicelli" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/fabridamicelli" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://linkedin.com/in/fabridamicelli" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.5090c770.min.js"></script>
      
    
  </body>
</html>